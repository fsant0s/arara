{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('../..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron.neurons import Neuron, User\n",
    "from neuron.neurons import Neuron\n",
    "from neuron.capabilities import DataFrameRetrieverCapability, RerankCapability\n",
    "from neuron.components import SequentialComponent, CycleComponent, Pipeline\n",
    "\n",
    "# Start logging\n",
    "from neuron.runtime_logging import start\n",
    "logging_session_id = start(config={\"dbname\": \"logs.db\"})\n",
    "print(\"Logging session ID: \" + str(logging_session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(r\"./data/yelp_academic_dataset_business.json\", lines=True, orient='columns', chunksize=1000000)\n",
    "# read the data \n",
    "for business in df:\n",
    "    business = business.head(100)\n",
    "    break\n",
    "\n",
    "business.drop(['business_id', 'is_open', 'hours', 'longitude', 'latitude', 'postal_code', 'state', 'city', 'attributes'], axis=1, inplace=True)\n",
    "business.rename(columns={'name': 'place_name'}, inplace=True)\n",
    "\n",
    "business['categories'] = business['categories'].str.split(', ')\n",
    "business = business.explode('categories', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config={\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama3-groq-70b-8192-tool-use-preview\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user = User(\n",
    "    name=\"User\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "extract_info_neuron = Neuron(\n",
    "    name=\"extract_info_neuron\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are an AI assistant tasked with extracting specific features from a user request. Your role is to identify and include only the features that are explicitly mentioned or can be directly inferred from the provided text. \n",
    "\n",
    "    ### Features to Extract:\n",
    "    1. 'stars' (ratings) as a numeric value.\n",
    "    2. 'review_count' as a numeric value.\n",
    "    3. 'categories' describing the business type. If not explicitly mentioned, infer from context or exclude it if unclear.\n",
    "\n",
    "    ### Output Format:\n",
    "    Include only the features that are explicitly mentioned or inferable, formatted as:\n",
    "    - stars is {stars_value}\n",
    "    - review_count is {review_count_value}\n",
    "    - categories is {categories_value}\n",
    "\n",
    "    ### Rules:\n",
    "    1. Include only the features described or inferable in the input. If a feature is not mentioned or cannot be inferred, do not include it in the output.\n",
    "    2. Provide only the extracted details. Do not leave placeholders or add features with empty values.\n",
    "    3. Do not include comments, explanations, or extra text in the output.\n",
    "\n",
    "    ### Examples:\n",
    "    1. Input: \"I want to eat pizza at a restaurant with at least 3 stars and more than 30 reviews.\"\n",
    "    Output: \n",
    "    stars is 3\n",
    "    review_count is 30\n",
    "    categories is Restaurant\n",
    "\n",
    "    2. Input: \"I need a clinic with at least 4 stars.\"\n",
    "    Output: \n",
    "    stars is 4\n",
    "    categories is Health & Medical\n",
    "\n",
    "    3. Input: \"Looking for a nice park with good views.\"\n",
    "    Output: \n",
    "    categories is Park\n",
    "\n",
    "    4. Input: \"I need something fun to do.\"\n",
    "    Output: \n",
    "    (No output)\n",
    "    \"\"\",\n",
    "    shared_memory_write_keys = [\"extract_info\"],\n",
    ")\n",
    "\n",
    "retriever_neuron = Neuron(\n",
    "    name=\"retriever_neuron\",\n",
    "    llm_config=llm_config, \n",
    "    system_message=\"\"\"\n",
    "    Format the retrieved items into a Python list of strings. Each string should include all item details in the format:\n",
    "\n",
    "    [\n",
    "        'Item 1: address is 123 Main St, categories is Shopping, place_name is Example Store, review_count is 10, stars is 4.0',\n",
    "        'Item 2: address is 456 Elm St, categories is Food, place_name is Example Cafe, review_count is 15, stars is 4.5'\n",
    "    ]\n",
    "\n",
    "    Output only the Python list of strings with all item details.\n",
    "    Remove any additional text, comments, or information. I mean, leave only the list of strings.\n",
    "    \"\"\"\n",
    ")\n",
    "data_frame_retriever_capability = DataFrameRetrieverCapability(\n",
    "    dataset=business, \n",
    "    columns = [\"stars\" , \"review_count\", \"categories\"],\n",
    "    cache=True,\n",
    "    top_n=10,\n",
    "    config= {\n",
    "        \"model\": \"gpt2-medium\",\n",
    "        \"model_dir\": r\"./models/erasmo_yelp_gpt2-medium_60_True\"\n",
    "    },\n",
    ")\n",
    "data_frame_retriever_capability.add_to_neuron(retriever_neuron)\n",
    "\n",
    "rerank_neuron = Neuron(\n",
    "    name=\"rerank_neuron\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "        You will be provided a list of item which were reranked. \n",
    "        Your goal is to create a short introduction about the list to the user.\n",
    "        Also, include all items in the list in the output.\n",
    "    \"\"\",\n",
    ")\n",
    "rerank_capability = RerankCapability(\n",
    "    rerank_model_name = \"rerank-english-v2.0\", #\"rerank-v3.5\",\n",
    "    api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "    top_n=10,\n",
    "    shared_memory_read_keys=[\"extract_info\"],\n",
    ")\n",
    "rerank_capability.add_to_neuron(rerank_neuron)\n",
    "\n",
    "assessor_neuron = Neuron(\n",
    "    name=\"assessor_neuron\",\n",
    "    llm_config=llm_config, \n",
    "    system_message=\"\"\"\n",
    "You are an Assessor assistant tasked with evaluating whether each retrieved item matches the user's specified criteria for `stars`, `review count`, and `category`.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Understand the User's Criteria:\n",
    "   - Identify the minimum requirements for `stars`, `review count`, and `category`.\n",
    "\n",
    "2. Evaluate Each Item:\n",
    "   - For each retrieved item, check:\n",
    "     - Does the `stars` value meet or exceed the user's requirement?\n",
    "     - Does the `review count` value meet or exceed the user's requirement?\n",
    "     - Does the `category` match the user's specified category?\n",
    "   - Respond for each item with:\n",
    "     - The item itself, followed by `\"Matches the user's criteria.\"` if it meets all requirements.\n",
    "     - The item itself, followed by `\"Does not match the user's criteria.\"` if it fails any requirement.\n",
    "\n",
    "3. Output:\n",
    "   - List each retrieved item alongside its evaluation in the format:\n",
    "     ```plaintext\n",
    "     Item: <item_details> - Matches the user's criteria.\n",
    "     Item: <item_details> - Does not match the user's criteria.\n",
    "     ```\n",
    "   - Ensure all items are included in the output.\n",
    "    \"\"\",\n",
    "    shared_memory_read_keys = [\"extract_info\"],\n",
    "    shared_memory_transition_message = [\"Below is the user's request:\"]\n",
    ")\n",
    "\n",
    "recommender = Neuron(\n",
    "    name=\"recommender\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    As a Recommender assistant, your task is to process the Assessor's item-by-item evaluation and return only the items that meet the user’s criteria.\n",
    "\n",
    "    ### Guidelines:\n",
    "\n",
    "    1. Understand the Inputs:\n",
    "    - You will receive the user's request and a list of item evaluations from the Assessor.\n",
    "\n",
    "    2. Filter Based on the Assessor's Evaluation:\n",
    "    - For each item evaluated as `\"Matches the user's criteria\"` by the Assessor, include it in your output.\n",
    "    - Exclude all items evaluated as `\"Does not match the user's criteria\"`.\n",
    "\n",
    "    3. Output the Matching Items:\n",
    "    - Return the exact details of the matching items, including all their attributes (e.g., name, location, stars, review count, category).\n",
    "    - If no items match, return a concise message:  \n",
    "        `\"No items match the user’s request.\"`\n",
    "\n",
    "    4. Be Precise and Minimalistic:\n",
    "    - Ensure the response contains only the matching items or the short message if no items match.\n",
    "    - Do not include any additional comments or explanations.\n",
    "    \"\"\",\n",
    "    shared_memory_read_keys=[\"extract_info\"],\n",
    "    shared_memory_transition_message=[\"Below is the user's request:\"],\n",
    "    shared_memory_write_keys=[\"recommend_items\"]\n",
    ")\n",
    "\n",
    "exaplainer = Neuron(\n",
    "    name=\"exaplainer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are an Explainer Assistant tasked with providing a clear explanation for the items recommended by the Recommender assistant based on the user's request. Your role is to justify the relevance of recommended items or explain why no items were recommended.\n",
    "\n",
    "    Inputs:\n",
    "    1. User Request: A description specifying the user's preferences or criteria.\n",
    "    2. Recommender Response: A list of recommended items or an indication that no items matched.\n",
    "\n",
    "    Guidelines:\n",
    "\n",
    "    1. Recommended Items:\n",
    "    - Begin with: \"For the recommended items, here is an explanation:\"\n",
    "    - For each item, provide:\n",
    "    - Item Name: [Name]\n",
    "    - Explanation: [How it meets the user's criteria, emphasizing key attributes like stars, review count, and category.]\n",
    "\n",
    "    2. No Recommendations:\n",
    "    - State: \"No items were recommended based on the user's request.\"\n",
    "    - Follow with: \"Here are the unmet criteria:\" and list the specific criteria not satisfied.\n",
    "\n",
    "    3. Output Format:\n",
    "    - For Recommended Items:\n",
    "    For the recommended items, here is an explanation:\n",
    "    Item Name: [Name]\n",
    "    Explanation: [Details about how it meets the user's request.]\n",
    "\n",
    "    - For No Recommendations:\n",
    "    No items were recommended based on the user's request.\n",
    "    Here are the unmet criteria:\n",
    "    - [Criterion 1]\n",
    "    - [Criterion 2]\n",
    "\n",
    "    Example Outputs:\n",
    "\n",
    "    Case 1: Recommended Items\n",
    "    For the recommended items, here is an explanation:\n",
    "    Item Name: \"Wireless Headphones\"\n",
    "    Explanation: \"Meets the criteria of 4.5 stars or higher, over 100 reviews, and the 'Electronics' category.\"\n",
    "\n",
    "    Item Name: \"Bluetooth Earbuds\"\n",
    "    Explanation: \"Satisfies the request for portability, high ratings, and the specified 'Electronics' category.\"\n",
    "\n",
    "    Case 2: No Recommendations\n",
    "    No items were recommended based on the user's request.\n",
    "    Here are the unmet criteria:\n",
    "    - Minimum rating of 4.0 stars.\n",
    "    - Category: 'Home Appliances'.\n",
    "\n",
    "    Tone:\n",
    "    - Be clear, concise, and focused on the user's criteria.\n",
    "    - Avoid redundant or overly technical language.\n",
    "    \"\"\",\n",
    "    shared_memory_read_keys=[\"extract_info\"],\n",
    "    shared_memory_transition_message=[\"Below is the user's request:\"],\n",
    ")\n",
    "\n",
    "evaluator = Neuron(\n",
    "    name=\"evaluator\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "   You are an Evaluator Assistant tasked with validating the consistency of the process, which includes the user’s request, recommended items, and the Explainer Assistant explanation. Your goal is to ensure the recommendations and explanations align with the user’s criteria.\n",
    "\n",
    "    Inputs:\n",
    "    1. User Request: The user’s criteria (e.g., stars, review count, category). Only consider explicitly mentioned features.\n",
    "    2. Recommended Items: The items provided by the Recommender assistant.\n",
    "    3. Explanation: The justification provided by the Explainer assistant.\n",
    "\n",
    "    Guidelines:\n",
    "\n",
    "    1. Validate Recommendations:\n",
    "    - Check if all recommended items meet the user’s explicitly described criteria.\n",
    "    - Disregard features not mentioned in the user’s request.\n",
    "\n",
    "    2. Verify Explanation:\n",
    "    - Confirm that the Explainer assistant explanation accurately reflects the attributes of the recommended items and aligns with the user’s request.\n",
    "    - Identify any mismatches between the explanation and the recommendations.\n",
    "\n",
    "    3. Output:\n",
    "    - If the process is consistent:\n",
    "    - Respond: \"The process is consistent. Here are the validated recommendations and explanations:\"\n",
    "    - List the recommended items with their attributes and the corresponding explanation.\n",
    "    - If the process is inconsistent:\n",
    "    - Respond: \"The evaluation failed due to the following issues:\"\n",
    "    - Specify:\n",
    "        - Items that do not meet the user’s criteria.\n",
    "        - Mismatches between the explanation and the recommendations or user’s request.\n",
    "\n",
    "    Example Outputs:\n",
    "\n",
    "    Case 1: Process is Consistent\n",
    "    \"The process is consistent. Here are the validated recommendations and explanations:\"\n",
    "    - Item: \"Wireless Headphones\"\n",
    "    Attributes: 4.5 stars, 150 reviews, Category: Electronics\n",
    "    Explanation: \"Meets the criteria of 4.5 stars or higher, over 100 reviews, and belongs to the requested category 'Electronics'.\"\n",
    "\n",
    "    - Item: \"Bluetooth Earbuds\"\n",
    "    Attributes: 4.8 stars, 200 reviews, Category: Electronics\n",
    "    Explanation: \"Satisfies the request for portability, high ratings, and the specified category 'Electronics'.\"\n",
    "\n",
    "    Case 2: Evaluation Failed\n",
    "    \"The evaluation failed due to the following issues:\"\n",
    "    - Item \"Bluetooth Earbuds\" does not meet the minimum review count.\n",
    "    - The explanation incorrectly states that all items meet the review count criteria.\n",
    "\n",
    "    Tone:\n",
    "    - Be direct and objective.\n",
    "    - Focus on clarity and relevance to the user’s criteria.\n",
    "    \"\"\",\n",
    "    shared_memory_read_keys=[\"extract_info\", \"recommend_items\"],\n",
    "    shared_memory_transition_message=[\"Below is the user's request:\", \"Items recommended:\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1 = CycleComponent(name=\"Cycle_1\", neurons=[extract_info_neuron, retriever_neuron, rerank_neuron, assessor_neuron], repetitions=1)\n",
    "sequential2 = SequentialComponent(name=\"Seq_1\", neurons=[recommender, exaplainer, evaluator])\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_edge(cycle_1, sequential2)\n",
    "pipeline.set_entry_point(cycle_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.initiate_chat(\n",
    "    #pipeline, message=\"I need a Health & Medical clinic with at least 1 stars and more than 5 reviews.\",\n",
    "    pipeline, message=\"Shopping outlet with at least 3 stars and more than 4 reviews.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('../..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "from neuron.runtime_logging import start\n",
    "logging_session_id = start(config={\"dbname\": \"logs.db\"})\n",
    "print(\"Logging session ID: \" + str(logging_session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron.components import SequentialComponent, CycleComponent, Pipeline\n",
    "from neuron.neurons import User, Neuron, RouterNeuron\n",
    "\n",
    "llm_config={\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"model\": \"llama3-groq-70b-8192-tool-use-preview\",\n",
    "            \"api_key\": \"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\",\n",
    "            \"temperature\": 0.0\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user = User(name=\"User\", llm_config=llm_config)\n",
    "\n",
    "common_seq1 = \"Dado um numero fornecido pelo usuario, vc deve adicionar mais um a esse numero. Seu output é somente o numero somado, sem texto adicional. Considere a ultima mensagem do user.\"\n",
    "common_seq2 = \"Dado um numero fornecido pelo usuario, vc deve adicionar mais dois a esse numero. Seu output é somente o numero somado, sem texto adicional. Considere a ultima mensagem do user.\"\n",
    "\n",
    "a1 = Neuron(name=\"Assistante 1\", llm_config=llm_config, system_message=common_seq1)\n",
    "seq1 = SequentialComponent(name=\"Sequential 1\", neurons=[a1])\n",
    "\n",
    "a0 = Neuron(name=\"Assistante 0\", llm_config=llm_config, system_message=\"Multiplica o numero fornecido pelo usuario por 2.\")\n",
    "seq0 = SequentialComponent(name=\"Sequential 0\", neurons=[a0])\n",
    "\n",
    "a2 = Neuron(name=\"Assistante 2\", llm_config=llm_config, system_message=common_seq1)\n",
    "a3 = Neuron(name=\"Assistante 3\", llm_config=llm_config, system_message=common_seq1)\n",
    "a4 = Neuron(name=\"Assistante 4\", llm_config=llm_config, system_message=common_seq1)\n",
    "\n",
    "cycle_router_neuron = Neuron(\n",
    "    name=\"Cycle Router\",\n",
    "    llm_config=llm_config,\n",
    "    system_message = \"\"\"\n",
    "    \"Evaluate the input based on the number provided by the user. Extract the number if it's part of a larger text. If the number is greater than 10, respond with 'TERMINATE' exactly, with no additional text or explanation. If the number is 10 or less, or if no number is provided, do not respond at all. For example, if the input is 'The number is 15,' reply 'TERMINATE.' If the input is 'The number is 5,' provide no response.\n",
    "    \"\"\",\n",
    ")\n",
    "cycle = CycleComponent(name=\"Cycle 1\", neurons=[a2, a3, a4], \n",
    "                       repetitions=1,\n",
    "                       default_component = seq0,\n",
    "                       cycle_router_neuron= cycle_router_neuron)\n",
    "\n",
    "\n",
    "a5 = Neuron(name=\"Assistante 5\", llm_config=llm_config, system_message=common_seq1)\n",
    "seq2 = SequentialComponent(name=\"Sequential 2\", neurons=[a5])\n",
    "\n",
    "a6 = Neuron(name=\"Assistante 6\", llm_config=llm_config, system_message=common_seq2)\n",
    "a7 = Neuron(name=\"Assistante 7\", llm_config=llm_config, system_message=common_seq2)\n",
    "seq3 = SequentialComponent(name=\"Sequential 3\", neurons=[a6, a7])\n",
    "\n",
    "\n",
    "router1 = RouterNeuron(\n",
    "    llm_config=llm_config,\n",
    "    name=\"router_1\",\n",
    "    route_mapping_function = lambda: {\"0\": \"continue\", \"1\": seq2, \"2\": seq3},\n",
    "    system_message = \"If the number is even, return '1'. If the number is odd, return '2'. Otherwise, return 'continue'.\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_edge(seq1, cycle)\n",
    "pipeline.add_edge(cycle, router1)\n",
    "pipeline.set_entry_point(seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.initiate_chat(\n",
    "    pipeline, message=\"Comece de 15\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
