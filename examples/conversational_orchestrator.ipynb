{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\.venv\\Lib\\site-packages\\accelerate\\utils\\other.py:220: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.multiarray.\n",
      "  np.core.multiarray._reconstruct,\n"
     ]
    }
   ],
   "source": [
    "from neuron.neurons import User, Neuron, ConversationalOrchestrator, ConversationalOrchestratorManager, UserTest\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"gemma2-9b-it\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user = User(\n",
    "    description=\"You are a human user interacting with conversational and recommendation agents.\"\n",
    ")\n",
    "\n",
    "conversational = Neuron(\n",
    "    name=\"conversational\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    \"You are an expert conversational agent skilled at natural interactions. Whenever the user requests recommendations or suggestions, immediately involve the recommender agent.\"\"\",\n",
    "    description=\"This agent acts as a social companion and facilitates interactions.\"\n",
    ")\n",
    "\n",
    "llm_config_2 = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama-3.3-70b-versatile\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "recommendation = Neuron(\n",
    "    name=\"recommender\",\n",
    "    llm_config=llm_config_2,\n",
    "    system_message=\"\"\"\n",
    "        You are an expert recommender agent. Whenever activated, you should clearly suggest the following items:\n",
    "            1. Shoes\n",
    "            2. T-shirts\n",
    "            3. Jeans\n",
    "Provide these suggestions directly when requested by the conversational agent or when the user explicitly asks for recommendations.\"\"\",\n",
    "    description=\"This agent specializes in offering product recommendations.\"\n",
    ")\n",
    "\n",
    "chitchat = ConversationalOrchestrator(\n",
    "    agents=[user, conversational, recommendation],\n",
    "    messages=[],\n",
    "    max_round=100,\n",
    "    speaker_selection_method=\"random\",\n",
    "    send_introductions=True,\n",
    "    allow_repeat_speaker = False,\n",
    ")\n",
    "\n",
    "chitchat_manager = ConversationalOrchestratorManager(chitchat=chitchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m[user ⟶ conversational_orchestrator]:\u001b[0m\n",
      "Oi tudo bem?\n",
      "original context: None\n",
      "all messages: [{'content': 'Chitchat manager.', 'role': 'system'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Hello everyone. We have assembled a great team today to answer questions and solve tasks. In attendance are:\\n\\nuser: You are a human user interacting with conversational and recommendation agents.\\nconversational: This agent acts as a social companion and facilitates interactions.\\nrecommender: This agent specializes in offering product recommendations.', 'name': 'conversational_orchestrator', 'role': 'assistant'}]\n",
      "to aqui,  {'messages': [{'content': 'Chitchat manager.', 'role': 'system'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Hello everyone. We have assembled a great team today to answer questions and solve tasks. In attendance are:\\n\\nuser: You are a human user interacting with conversational and recommendation agents.\\nconversational: This agent acts as a social companion and facilitates interactions.\\nrecommender: This agent specializes in offering product recommendations.', 'name': 'conversational_orchestrator', 'role': 'assistant'}], 'tools': [], 'cache': None, 'client': 'groq', 'temperature': 0.0, 'model': 'gemma2-9b-it'}\n",
      "\u001b[1m\u001b[36m[conversational_orchestrator ⟶ user]:\u001b[0m\n",
      "\n",
      "\n",
      "Please let us know how we can help you!\n",
      "\n",
      "original context: None\n",
      "all messages: [{'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'role': 'system', 'content': 'Summarize the takeaway from the conversation in a contextualized manner, providing a detailed summary of all parties involved, without adding introductory phrases'}]\n",
      "to aqui,  {'messages': [{'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'content': 'Oi tudo bem?', 'name': 'user', 'role': 'user'}, {'role': 'system', 'content': 'Summarize the takeaway from the conversation in a contextualized manner, providing a detailed summary of all parties involved, without adding introductory phrases'}], 'tools': [], 'cache': None, 'client': 'groq', 'temperature': 0.0, 'model': 'gemma2-9b-it'}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TextMessage\ntarget\n  Input should be an instance of BaseNeuron [type=is_instance_of, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chat_result \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchitchat_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOi tudo bem?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflection_with_llm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\neuron\\neurons\\neuron.py:371\u001b[0m, in \u001b[0;36mNeuron.initiate_chat\u001b[1;34m(self, recipient, should_clear_history, silent, message, summary_method, summary_args, cache, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m stream \u001b[38;5;241m=\u001b[39m chain([msg2send], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg2send, recipient, silent\u001b[38;5;241m=\u001b[39msilent))\n\u001b[0;32m    369\u001b[0m Console(stream)\n\u001b[1;32m--> 371\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summarize_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m     \u001b[49m\u001b[43msummary_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m       \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n\u001b[0;32m    379\u001b[0m     agent\u001b[38;5;241m.\u001b[39mclient_cache \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mprevious_cache\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\neuron\\neurons\\neuron.py:700\u001b[0m, in \u001b[0;36mNeuron._summarize_chat\u001b[1;34m(self, summary_method, summary_args, recipient, cache)\u001b[0m\n\u001b[0;32m    697\u001b[0m     summary_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_msg_as_summary\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(summary_method, Callable):\n\u001b[1;32m--> 700\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf not None, the summary_method must be a string from [`reflection_with_llm`, `last_msg`] or a callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\neuron\\neurons\\neuron.py:736\u001b[0m, in \u001b[0;36mNeuron._reflection_with_llm_as_summary\u001b[1;34m(sender, recipient, summary_args)\u001b[0m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe summary_role in summary_arg must be a string.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 736\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43mreflection_with_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrole\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    740\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot extract summary using reflection_with_llm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Using an empty str as summary.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\neuron\\neurons\\helpers\\reflection_with_llm.py:40\u001b[0m, in \u001b[0;36mreflection_with_llm\u001b[1;34m(sender, prompt, messages, llm_agent, cache, role)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo OpenAIWrapper client is found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_oai_reply_from_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\neuron\\neurons\\neuron.py:567\u001b[0m, in \u001b[0;36mNeuron._generate_oai_reply_from_client\u001b[1;34m(self, llm_client, messages, cache, sender)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall messages:\u001b[39m\u001b[38;5;124m\"\u001b[39m, all_messages)\n\u001b[0;32m    559\u001b[0m response \u001b[38;5;241m=\u001b[39m llm_client\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    560\u001b[0m     context\u001b[38;5;241m=\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    561\u001b[0m     messages\u001b[38;5;241m=\u001b[39mall_messages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    564\u001b[0m     neuron\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    565\u001b[0m )\n\u001b[1;32m--> 567\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_event\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_model_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_messages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcancellation_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_messages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandoff_tools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhandoff_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#handoffs=handoffs,\u001b[39;49;00m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_client_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_client_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreflect_on_tool_use\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreflect_on_tool_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_call_summary_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_call_summary_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mself_reflection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_reflection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_event\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\neuron\\neurons\\neuron.py:876\u001b[0m, in \u001b[0;36mNeuron._process_model_result\u001b[1;34m(cls, model_result, inner_messages, cancellation_token, source, target, system_messages, model_context, tools, handoff_tools, model_client, model_client_stream, reflect_on_tool_use, tool_call_summary_format, self_reflection)\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m Response(\n\u001b[1;32m--> 876\u001b[0m             chat_message\u001b[38;5;241m=\u001b[39m\u001b[43mTextMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodels_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    882\u001b[0m             inner_messages\u001b[38;5;241m=\u001b[39minner_messages,\n\u001b[0;32m    883\u001b[0m         )\n\u001b[0;32m    884\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;66;03m# Otherwise, we have function calls\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\.venv\\Lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for TextMessage\ntarget\n  Input should be an instance of BaseNeuron [type=is_instance_of, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/is_instance_of"
     ]
    }
   ],
   "source": [
    "chat_result = user.initiate_chat(\n",
    "    chitchat_manager, message=\"Oi tudo bem?\", summary_method=\"reflection_with_llm\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
