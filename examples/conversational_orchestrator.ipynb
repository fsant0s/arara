{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron.neurons import User, Neuron, ConversationalOrchestrator, ConversationalOrchestratorManager, UserTest\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user = User(\n",
    "    description=\"You are a human user interacting with conversational and recommendation agents.\"\n",
    ")\n",
    "\n",
    "conversational = Neuron(\n",
    "    name=\"conversational\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are a friendly Conversation AI.\n",
    "Your job is to handle all general interactions naturally and pleasantly.\n",
    "\n",
    "When a user asks for recommendations (such as requesting suggestions or asking for advice on choosing something), **you must immediately pass the request to the Recommender**.\n",
    "\n",
    "- In case of a recommendation request, reply with: \"Let me connect you with our Recommender to help with that!\" and do not answer directly.\n",
    "- Otherwise, continue interacting normally, answering questions, chatting, and helping the user in a casual, supportive tone.\n",
    "- Always maintain a positive and welcoming attitude.\n",
    "\n",
    "Focus on keeping the conversation flowing unless a specialist (like the Recommender) is needed.\n",
    "\n",
    "\"\"\",\n",
    "    description=\"This agent acts as a social companion and facilitates interactions.\"\n",
    ")\n",
    "\n",
    "llm_config_2 = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "recommendation = Neuron(\n",
    "    name=\"recommender\",\n",
    "    llm_config=llm_config_2,\n",
    "    system_message=\"\"\"\n",
    "    You are a specialized Recommender AI.\n",
    "Your role is to respond directly to user requests for recommendations.\n",
    "\n",
    "When the user asks for recommendations (such as suggesting products, services, options, or anything similar), you must respond clearly and directly, providing a concise list or a short explanation.\n",
    "\n",
    "- Never decline a recommendation request.\n",
    "- Keep your responses focused only on recommending options.\n",
    "- Do not ask questions unless necessary for a better recommendation.\n",
    "- Stay friendly and helpful.\n",
    "\n",
    "Examples of valid requests you should handle:\n",
    "- \"Can you recommend a good restaurant?\"\n",
    "- \"Suggest a book to read.\"\n",
    "- \"What laptop should I buy?\"\n",
    "\n",
    "Always take the initiative to recommend something relevant, even if the user's question is vague.\n",
    "\n",
    "\"\"\",\n",
    "    description=\"This agent specializes in offering product recommendations.\"\n",
    ")\n",
    "\n",
    "chitchat = ConversationalOrchestrator(\n",
    "    agents=[user, conversational, recommendation],\n",
    "    messages=[],\n",
    "    max_round=100,\n",
    "    speaker_selection_method=\"auto\",\n",
    "    #send_introductions=True,\n",
    "    allow_repeat_speaker = False,\n",
    ")\n",
    "\n",
    "chitchat_manager = ConversationalOrchestratorManager(chitchat=chitchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = user.initiate_chat(\n",
    "    chitchat_manager, message=\"Oi tudo bem?\",\n",
    "    cache=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user._oai_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational._oai_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
