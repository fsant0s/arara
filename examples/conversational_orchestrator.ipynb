{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron.neurons import User, Neuron, ConversationalOrchestrator, ConversationalOrchestratorManager\n",
    "from neuron.neurons.scripted_users import UserConversationalOrchestrator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama-3.3-70b-versatile\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user = UserConversationalOrchestrator(\n",
    "    description=\"You are a human user interacting with conversational and recommendation agents.\"\n",
    ")\n",
    "\n",
    "conversational = Neuron(\n",
    "    name=\"conversational\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are a conversational agent.\n",
    "\n",
    "    Your role is to respond to general user input with brief, friendly, and natural replies.\n",
    "    You are not responsible for providing recommendations or opinions about movies, products, or any other content.\n",
    "\n",
    "    Keep your responses simple, casual, and focused only on maintaining a natural conversation.\n",
    "\"\"\",\n",
    "    description=\"This agent acts as a social companion and facilitates interactions.\"\n",
    ")\n",
    "\n",
    "llm_config_2 = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "recommendation = Neuron(\n",
    "    name=\"recommender\",\n",
    "    llm_config=llm_config_2,\n",
    "    system_message=\"\"\"\n",
    "    You are a movie recommendation agent.\n",
    "\n",
    "    Your role is to respond with exactly 3 movie suggestions whenever the user asks for a recommendation.\n",
    "\n",
    "    Always respond directly with the following 3 movies:\n",
    "\n",
    "    1. The Shawshank Redemption (1994) – A powerful story of hope and friendship set in a prison.\n",
    "    2. Inception (2010) – A mind-bending sci-fi thriller about dreams within dreams.\n",
    "    3. Parasite (2019) – A gripping social satire that blends drama, suspense, and dark comedy.\n",
    "\n",
    "    Do not ask follow-up questions, introduce yourself, apologize, or explain your reasoning.\n",
    "    Simply return the 3 movies above, and nothing else.\n",
    "\"\"\",\n",
    "    description=\"This agent specializes in recommending movies.\"\n",
    ")\n",
    "\n",
    "chitchat = ConversationalOrchestrator(\n",
    "    agents=[user, conversational, recommendation],\n",
    "    messages=[],\n",
    "    max_round=100,\n",
    "    speaker_selection_method=\"auto\",\n",
    "    #send_introductions=True,\n",
    "    allow_repeat_speaker = False,\n",
    ")\n",
    "\n",
    "chitchat_manager = ConversationalOrchestratorManager(chitchat=chitchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36muser_conversational ⟶ conversational_orchestrator:\u001b[0m\n",
      "Hey, how are you doing today?\n",
      "model_result finish_reason='stop' content='conversational' usage=RequestUsage(prompt_tokens=143, completion_tokens=4, total_tokens=147) cached=False logprobs=None thought=None response_id='chatcmpl-2d32502b-1a66-47fc-a0fd-8509c5db2020' cost=8.753e-05 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x00000178B7F452B0>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: conversational\n",
      "\u001b[0m\n",
      "model_result finish_reason='stop' content=\"I'm doing well, thanks for asking. How about you, how's your day going so far?\" usage=RequestUsage(prompt_tokens=106, completion_tokens=22, total_tokens=128) cached=False logprobs=None thought=None response_id='chatcmpl-99c5f0bf-bcb3-4ecc-8327-fdf26fd8ba8e' cost=7.992000000000001e-05 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788AAF7500>> config_id=0 pass_filter=True\n",
      "\u001b[36mconversational ⟶ conversational_orchestrator:\u001b[0m\n",
      "I'm doing well, thanks for asking. How about you, how's your day going so far?\n",
      "model_result finish_reason='stop' content='user_conversational' usage=RequestUsage(prompt_tokens=175, completion_tokens=5, total_tokens=180) cached=False logprobs=None thought=None response_id='chatcmpl-74ae0281-3d72-44ba-a50a-9bba213ac2e8' cost=0.0001072 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x00000178B7F9A9F0>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: user_conversational\n",
      "\u001b[0m\n",
      "\u001b[36muser_conversational ⟶ conversational_orchestrator:\u001b[0m\n",
      "I'm thinking about watching something tonight. Can you recommend me a good movie to relax?\n",
      "model_result finish_reason='stop' content='recommender' usage=RequestUsage(prompt_tokens=192, completion_tokens=4, total_tokens=196) cached=False logprobs=None thought=None response_id='chatcmpl-6e5cba7c-fa31-47e5-8a35-f2fcf4c48ed1' cost=0.00011644000000000002 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788CCC9B50>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: recommender\n",
      "\u001b[0m\n",
      "model_result finish_reason='stop' content='1. The Shawshank Redemption (1994) – A powerful story of hope and friendship set in a prison.\\n2. Inception (2010) – A mind-bending sci-fi thriller about dreams within dreams.\\n3. Parasite (2019) – A gripping social satire that blends drama, suspense, and dark comedy.' usage=RequestUsage(prompt_tokens=226, completion_tokens=69, total_tokens=295) cached=False logprobs=None thought=None response_id='chatcmpl-8a36e536-6614-484f-a01c-7aca430f061a' cost=0.00018785000000000004 model_name='llama3-70b-8192' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x00000178B7F45310>> config_id=0 pass_filter=True\n",
      "\u001b[36mrecommender ⟶ conversational_orchestrator:\u001b[0m\n",
      "1. The Shawshank Redemption (1994) – A powerful story of hope and friendship set in a prison.\n",
      "2. Inception (2010) – A mind-bending sci-fi thriller about dreams within dreams.\n",
      "3. Parasite (2019) – A gripping social satire that blends drama, suspense, and dark comedy.\n",
      "model_result finish_reason='stop' content='conversational' usage=RequestUsage(prompt_tokens=275, completion_tokens=4, total_tokens=279) cached=False logprobs=None thought=None response_id='chatcmpl-acb89d1a-af9f-4690-b10f-4cf04d2cb186' cost=0.00016541 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788CCCA870>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: conversational\n",
      "\u001b[0m\n",
      "model_result finish_reason='stop' content='Those all sound like great movies. What kind of mood are you in tonight? Are you looking for something light and easy to watch, or something a bit more thought-provoking?' usage=RequestUsage(prompt_tokens=228, completion_tokens=38, total_tokens=266) cached=False logprobs=None thought=None response_id='chatcmpl-49d78645-2e10-4bdb-b01f-fe681fdda26e' cost=0.00016454000000000002 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788AAF7500>> config_id=0 pass_filter=True\n",
      "\u001b[36mconversational ⟶ conversational_orchestrator:\u001b[0m\n",
      "Those all sound like great movies. What kind of mood are you in tonight? Are you looking for something light and easy to watch, or something a bit more thought-provoking?\n",
      "model_result finish_reason='stop' content='user_conversational' usage=RequestUsage(prompt_tokens=313, completion_tokens=5, total_tokens=318) cached=False logprobs=None thought=None response_id='chatcmpl-46c2d905-c25b-4fa0-83cc-cfcf231f2df3' cost=0.00018862 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788CCC50D0>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: user_conversational\n",
      "\u001b[0m\n",
      "\u001b[36muser_conversational ⟶ conversational_orchestrator:\u001b[0m\n",
      "Thanks! That sounds great.\n",
      "model_result finish_reason='stop' content='conversational' usage=RequestUsage(prompt_tokens=318, completion_tokens=4, total_tokens=322) cached=False logprobs=None thought=None response_id='chatcmpl-16e2e6a2-6a9b-40d1-9753-d981edded6e5' cost=0.00019078 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788CCC7140>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: conversational\n",
      "\u001b[0m\n",
      "model_result finish_reason='stop' content=\"So, what do you think you'll end up watching tonight?\" usage=RequestUsage(prompt_tokens=281, completion_tokens=14, total_tokens=295) cached=False logprobs=None thought=None response_id='chatcmpl-8ebe95be-28d9-4f1e-bdfe-a01b7ad490a0' cost=0.00017685000000000002 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x000001788AAF7500>> config_id=0 pass_filter=True\n",
      "\u001b[36mconversational ⟶ conversational_orchestrator:\u001b[0m\n",
      "So, what do you think you'll end up watching tonight?\n",
      "model_result finish_reason='stop' content='user_conversational' usage=RequestUsage(prompt_tokens=342, completion_tokens=5, total_tokens=347) cached=False logprobs=None thought=None response_id='chatcmpl-263cb97c-b500-4386-b24e-fa5d2a0eb9ca' cost=0.00020573000000000002 model_name='llama-3.3-70b-versatile' message_retrieval_function=<bound method GroqClient.message_retrieval of <neuron.capabilities.clients.models.groq.GroqClient object at 0x00000178B7FB5580>> config_id=0 pass_filter=True\n",
      "\u001b[32m\n",
      "Next speaker: user_conversational\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_result = user.initiate_chat(\n",
    "    chitchat_manager, message=\"Hey, how are you doing today?\",\n",
    "    cache=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Hey, how are you doing today?', 'role': 'assistant', 'name': 'user_conversational'}, {'content': \"I'm doing well, thanks for asking. How about you, how's your day going so far?\", 'name': 'conversational', 'role': 'user'}, {'content': \"I'm thinking about watching something tonight. Can you recommend me a good movie to relax?\", 'role': 'assistant', 'name': 'user_conversational'}, {'content': '1. The Shawshank Redemption (1994) – A powerful story of hope and friendship set in a prison.\\n2. Inception (2010) – A mind-bending sci-fi thriller about dreams within dreams.\\n3. Parasite (2019) – A gripping social satire that blends drama, suspense, and dark comedy.', 'name': 'recommender', 'role': 'user'}, {'content': 'Those all sound like great movies. What kind of mood are you in tonight? Are you looking for something light and easy to watch, or something a bit more thought-provoking?', 'name': 'conversational', 'role': 'user'}, {'content': 'Thanks! That sounds great.', 'role': 'assistant', 'name': 'user_conversational'}, {'content': \"So, what do you think you'll end up watching tonight?\", 'name': 'conversational', 'role': 'user'}], summary=\"So, what do you think you'll end up watching tonight?\", cost={'usage_including_cached_inference': {'total_cost': 0.00167087, 'speaker_selection_agent': {'total_cost': 0.00106171, 'llama-3.3-70b-versatile': {'cost': 0.00106171, 'prompt_tokens': 1758, 'completion_tokens': 31, 'total_tokens': 1789}}, 'conversational': {'total_cost': 0.00042131000000000004, 'llama-3.3-70b-versatile': {'cost': 0.00042131000000000004, 'prompt_tokens': 615, 'completion_tokens': 74, 'total_tokens': 689}}, 'recommender': {'total_cost': 0.00018785000000000004, 'llama3-70b-8192': {'cost': 0.00018785000000000004, 'prompt_tokens': 226, 'completion_tokens': 69, 'total_tokens': 295}}}, 'usage_excluding_cached_inference': {'total_cost': 0.00167087, 'speaker_selection_agent': {'total_cost': 0.00106171, 'llama-3.3-70b-versatile': {'cost': 0.00106171, 'prompt_tokens': 1758, 'completion_tokens': 31, 'total_tokens': 1789}}, 'conversational': {'total_cost': 0.00042131000000000004, 'llama-3.3-70b-versatile': {'cost': 0.00042131000000000004, 'prompt_tokens': 615, 'completion_tokens': 74, 'total_tokens': 689}}, 'recommender': {'total_cost': 0.00018785000000000004, 'llama3-70b-8192': {'cost': 0.00018785000000000004, 'prompt_tokens': 226, 'completion_tokens': 69, 'total_tokens': 295}}}}, human_input=[\"I'm thinking about watching something tonight. Can you recommend me a good movie to relax?\", 'Thanks! That sounds great.', 'exit'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
