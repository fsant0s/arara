{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FS-Ma\\OneDrive\\Documents\\projects\\neuron\\.venv\\Lib\\site-packages\\accelerate\\utils\\other.py:220: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.multiarray.\n",
      "  np.core.multiarray._reconstruct,\n"
     ]
    }
   ],
   "source": [
    "from neuron.neurons import User, Neuron, ConversationalOrchestrator, ConversationalOrchestratorManager, UserTest\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user = User(\n",
    "    description=\"You are a human user interacting with conversational and recommendation agents.\"\n",
    ")\n",
    "\n",
    "conversational = Neuron(\n",
    "    name=\"conversational\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    \"You are an expert conversational agent skilled at natural interactions. Whenever the user requests recommendations or suggestions, immediately involve the recommender agent.\"\"\",\n",
    "    description=\"This agent acts as a social companion and facilitates interactions.\"\n",
    ")\n",
    "\n",
    "llm_config_2 = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"client\": \"groq\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"model\": \"llama-3.3-70b-versatile\",\n",
    "            \"api_key\": os.getenv(\"GROQ_API_KEY\")\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "recommendation = Neuron(\n",
    "    name=\"recommender\",\n",
    "    llm_config=llm_config_2,\n",
    "    system_message=\"\"\"\n",
    "        You are an expert recommender agent. Whenever activated, you should clearly suggest the following items:\n",
    "            1. Shoes\n",
    "            2. T-shirts\n",
    "            3. Jeans\n",
    "Provide these suggestions directly when requested by the conversational agent or when the user explicitly asks for recommendations.\"\"\",\n",
    "    description=\"This agent specializes in offering product recommendations.\"\n",
    ")\n",
    "\n",
    "explainer = Neuron(\n",
    "    name=\"explainer\",\n",
    "    llm_config=llm_config_2,\n",
    "    system_message=\"\"\"\n",
    "        You are an expert explainer agent. Whenever activated, you should clearly explain the following items:\n",
    "            1. Shoes\n",
    "            2. T-shirts\n",
    "            3. Jeans\n",
    "Provide these explanations directly when requested by the conversational agent or when the user explicitly asks for explanations.\"\"\",\n",
    "    description=\"This agent specializes in offering product explanations.\"\n",
    ")\n",
    "cretical = Neuron(\n",
    "    name=\"critical\",\n",
    "    llm_config=llm_config_2,\n",
    "    system_message=\"\"\"\n",
    "        You are an expert critical agent. Whenever activated, you should clearly critique the following items:\n",
    "            1. Shoes\n",
    "            2. T-shirts\n",
    "            3. Jeans\n",
    "Provide these critiques directly when requested by the conversational agent or when the user explicitly asks for critiques.\"\"\",\n",
    "    description=\"This agent specializes in offering product critiques.\"\n",
    ")\n",
    "modules = ConversationalOrchestrator(\n",
    "    agents=[explainer, cretical],\n",
    "    messages=[],\n",
    "    max_round=1,\n",
    "    speaker_selection_method=\"auto\",\n",
    "    send_introductions=True,\n",
    "    allow_repeat_speaker = False,\n",
    ")\n",
    "modules_manager = ConversationalOrchestratorManager(chitchat=modules, llm_config=llm_config)\n",
    "\n",
    "chitchat = ConversationalOrchestrator(\n",
    "    agents=[user, conversational, recommendation],\n",
    "    messages=[],\n",
    "    max_round=100,\n",
    "    speaker_selection_method=\"auto\",\n",
    "    send_introductions=True,\n",
    "    allow_repeat_speaker = False,\n",
    ")\n",
    "\n",
    "chitchat_manager = ConversationalOrchestratorManager(chitchat=chitchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silent: False\n",
      "\u001b[1m\u001b[36m[user ⟶ conversational_orchestrator]:\u001b[0m\n",
      "Oi tudo bem?\n",
      "silent: True\n",
      "\u001b[1m\u001b[36m[checking_agent ⟶ speaker_selection_agent]:\u001b[0m\n",
      "Read the above conversation. Then select the next role from ['conversational', 'recommender'] to play. Only return the role.\n",
      "\u001b[1m\u001b[36m[speaker_selection_agent ⟶ checking_agent]:\u001b[0m\n",
      "conversational\n",
      "\u001b[32m\n",
      "Next speaker: conversational\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[36m[conversational ⟶ conversational_orchestrator]:\u001b[0m\n",
      "Olá! Tudo bem, obrigado! É um prazer conversar com você. Como posso ajudá-lo hoje?\n",
      "silent: True\n",
      "\u001b[1m\u001b[36m[checking_agent ⟶ speaker_selection_agent]:\u001b[0m\n",
      "Read the above conversation. Then select the next role from ['user', 'recommender'] to play. Only return the role.\n",
      "\u001b[1m\u001b[36m[speaker_selection_agent ⟶ checking_agent]:\u001b[0m\n",
      "user\n",
      "\u001b[32m\n",
      "Next speaker: user\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[36m[conversational_orchestrator ⟶ user]:\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_result = user.initiate_chat(\n",
    "    chitchat_manager, message=\"Oi tudo bem?\", summary_method=\"reflection_with_llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Oi tudo bem?', 'name': 'user', 'role': 'assistant'}, {'content': 'Hello everyone. We have assembled a great team today to answer questions and solve tasks. In attendance are:\\n\\nuser: You are a human user interacting with conversational and recommendation agents.\\nconversational: This agent acts as a social companion and facilitates interactions.\\nrecommender: This agent specializes in offering product recommendations.', 'name': 'conversational_orchestrator', 'role': 'user'}, {'content': 'Olá! Tudo bem, obrigado! É um prazer conversar com você. Como posso ajudá-lo hoje?', 'name': 'conversational_orchestrator', 'role': 'user'}, {'content': 'Olá! Tudo bem, obrigado! É um prazer conversar com você. Como posso ajudá-lo hoje?', 'name': 'conversational_orchestrator', 'role': 'user'}, {'content': '', 'name': 'conversational_orchestrator', 'role': 'user'}, {'content': 'Olá! Tudo bem, obrigado! É um prazer conversar com você. Como posso ajudá-lo hoje?', 'name': 'conversational_orchestrator', 'role': 'user'}, {'content': '', 'name': 'conversational_orchestrator', 'role': 'user'}], summary=[Response(chat_message=TextMessage(source=<neuron.neurons.user.User object at 0x0000018DE5D84050>, target=<neuron.neurons.user.User object at 0x0000018DE5D84050>, models_usage=RequestUsage(prompt_tokens=83, completion_tokens=65, total_tokens=148), metadata={}, content='There is no conversation to summarize as this conversation has just started. The conversation is in Portuguese and it appears to be a greeting exchange between two parties. One party initiated the conversation with \"Oi tudo bem?\" which means \"Hi, how are you?\" and the other party responded with a greeting and an offer to help.', type='TextMessage'), inner_messages=[])], cost={'usage_including_cached_inference': {'total_cost': 0.00019610000000000002, 'llama3-70b-8192': {'cost': 0.00019610000000000002, 'prompt_tokens': 244, 'completion_tokens': 66, 'total_tokens': 310}}, 'usage_excluding_cached_inference': {'total_cost': 0.00019610000000000002, 'llama3-70b-8192': {'cost': 0.00019610000000000002, 'prompt_tokens': 244, 'completion_tokens': 66, 'total_tokens': 310}}}, human_input=['exit'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {<neuron.neurons.conversational_orchestrator.ConversationalOrchestratorManager at 0x18de55f5df0>: [{'content': 'Hello everyone. We have assembled a great team today to answer questions and solve tasks. In attendance are:\\n\\nuser: You are a human user interacting with conversational and recommendation agents.\\nconversational: This agent acts as a social companion and facilitates interactions.\\nrecommender: This agent specializes in offering product recommendations.',\n",
       "               'name': 'conversational_orchestrator',\n",
       "               'role': 'user'},\n",
       "              {'content': 'Oi tudo bem?',\n",
       "               'name': 'conversational_orchestrator',\n",
       "               'role': 'user'},\n",
       "              {'content': 'Olá! Tudo bem, obrigado! É um prazer conversar com você. Como posso ajudá-lo hoje?',\n",
       "               'name': 'conversational',\n",
       "               'role': 'assistant'}]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational._oai_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
