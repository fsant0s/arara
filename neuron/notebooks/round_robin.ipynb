{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('../..')\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FS-Ma\\miniconda3\\envs\\neuron\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging session ID: 644985c9-9f0c-4a10-a14f-00623fe24d5c\n"
     ]
    }
   ],
   "source": [
    "from neuron.runtime_logging import start\n",
    "from neuron.agents import UserAgent\n",
    "from neuron.agents.agents import LearnerAgent, KnowledgeRepresenterAgent\n",
    "from neuron.agents.llm_agents import PerceiverAgent\n",
    "from neuron.scenarios import RoundRobin, RoundRobinManager\n",
    "\n",
    "from neuron.capabilities.perceiver import SemanticTemplateFillerCapability\n",
    "\n",
    "# Start logging\n",
    "logging_session_id = start(config={\"dbname\": \"logs.db\"})\n",
    "print(\"Logging session ID: \" + str(logging_session_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"C:/Users/FS-Ma/OneDrive/Documents/projects/neuron/data/yelp_academic_dataset_business.json\", lines=True, orient='columns', chunksize=1000000)\n",
    "# read the data \n",
    "for business in df:\n",
    "    business = business\n",
    "    break\n",
    "business.drop(['business_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FS-Ma\\miniconda3\\envs\\neuron\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\FS-Ma\\miniconda3\\envs\\neuron\\lib\\site-packages\\be_great\\great.py:487: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  great.model.load_state_dict(torch.load(path + \"/model.pt\", map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "I like sushi e meu nome é sildofo e meus reviews_count são 10 eu sou gosto de restaurantes com 10 estrelas.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mperceiver_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\n",
      "    \"name\": [\"sildofo\"],\n",
      "    \"address\": [np.nan],\n",
      "    \"city\": [np.nan],\n",
      "    \"state\": [np.nan],\n",
      "    \"postal_code\": [np.nan],\n",
      "    \"latitude\": [np.nan],\n",
      "    \"longitude\": [np.nan],\n",
      "    \"stars\": [\"10\"],\n",
      "    \"review_count\": [\"10\"],\n",
      "    \"is_open\": [np.nan],\n",
      "    \"attributes\": [np.nan],\n",
      "    \"categories\": [np.nan],\n",
      "    \"hours\": [np.nan]\n",
      "}\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mlearner_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "name is sildofo, address is 5275 W Sunset Blvd, city is Las Vegas, state is placeholder, postal_code is 89031, latitude is 36.1238804, longitude is -115.122655, stars is 10.0, review_count is 10.0, is_open is 1.0, attributes is placeholder, categories is Shopping, hours is {'Monday': '11:0-17:0'\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_config={\n",
    "    \"config_list\": [{\n",
    "        \"client\": \"groq\",\n",
    "        \"model\": \"llama3-groq-70b-8192-tool-use-preview\",\n",
    "        \"api_key\": \"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\"\n",
    "        }\n",
    "]}\n",
    "\n",
    "user_agent = UserAgent(\n",
    "    name=\"User Agent\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "perceiver_agent = PerceiverAgent(\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "leaner_agent = LearnerAgent(\n",
    "    llm_config = {\n",
    "    \"config_list\": [{\n",
    "        \"client\": \"Begreat\",\n",
    "        \"model\": \"distilgpt2\",\n",
    "        \"model_dir\": \"C:/Users/FS-Ma/OneDrive/Documents/projects/neuron/models/be_great_yelp\",\n",
    "    }]},\n",
    ")\n",
    "\n",
    "#knowledge_representer_agent = KnowledgeRepresenterAgent(\n",
    "#    system_message=\"You are responsible to generate representations of the information.\",\n",
    "#    llm_config= {\n",
    "#        \"config_list\": [{\n",
    "#            \"client\": \"LLMEmbedding\",\n",
    "#            \"usage_type \": \"embeddings\", # // or \"embeddings\", \"classification\", etc.\n",
    "#            \"model_dir\": \"C:/Users/FS-Ma/OneDrive/Documents/projects/neuron/models/erasmo_yelp_gpt2-medium_60_True\",\n",
    "#            \"model_name\": \"gpt2-medium\"\n",
    "#    }]},\n",
    "#)\n",
    "\n",
    "\n",
    "semantic_template_filler = SemanticTemplateFillerCapability(row=business.iloc[0], llm_config=llm_config)\n",
    "semantic_template_filler.add_to_agent(perceiver_agent)\n",
    "\n",
    "groupchat = RoundRobin(agents=[user_agent, perceiver_agent, leaner_agent], messages=[])\n",
    "manager = RoundRobinManager(groupchat=groupchat, llm_config=None)\n",
    "\n",
    "user_agent.initiate_chat(\n",
    "    manager, message=\"I like sushi e meu nome é sildofo e meus reviews_count são 10 eu sou gosto de restaurantes com 10 estrelas.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autorec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
